{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"HALO Core Docs","text":"<p>Welcome to the HALO Core documentation site.</p> <p>This site is the public docs entry point for setup, architecture, and day-to-day development.</p>"},{"location":"#start-here","title":"Start here","text":"<ul> <li>Getting Started</li> <li>Repository Overview</li> <li>Architecture and Runtime</li> <li>Agent System</li> <li>Data Storage and Retrieval</li> <li>UI Panels and Pages</li> <li>Development, Testing, and Operations</li> </ul> <p>Made with \u2764\ufe0f by Corpus Analytica</p>"},{"location":"agent-system/","title":"HALO Core Agent System and Configuration","text":""},{"location":"agent-system/#1-overview","title":"1) Overview","text":"<p>HALO Core uses Agno agents and teams with a configuration-first approach:</p> <ul> <li>Per-agent JSON config files under <code>HALO_DATA_DIR/agents/</code></li> <li>A master chat agent/team config (<code>chat</code>)</li> <li>Deterministic routing modes for delegation</li> <li>Preset overlays to quickly switch model/tools/members at runtime</li> </ul> <p>The UI edits configs, but core behavior is implemented in <code>services/</code>.</p>"},{"location":"agent-system/#2-agent-configuration-schema","title":"2) Agent configuration schema","text":"<p>The canonical schema lives in <code>services/agents_config.py</code> (<code>AgentConfig</code> model).</p> <p>Supported fields:</p> <ul> <li>identity and metadata:</li> <li><code>id</code>, <code>name</code>, <code>description</code>, <code>role</code></li> <li>behavior:</li> <li><code>instructions</code></li> <li><code>skills</code></li> <li><code>tools</code></li> <li><code>mcp_calls</code></li> <li>runtime:</li> <li><code>model</code></li> <li><code>coordination_mode</code></li> <li><code>stream_events</code></li> <li><code>memory_scope</code></li> <li><code>enabled</code></li> <li><code>members</code></li> <li><code>tool_settings</code></li> </ul> <p>Validation behavior:</p> <ul> <li><code>instructions</code> accepts <code>str</code> or <code>list[str]</code>, normalized to a single string</li> <li>list fields (<code>skills</code>, <code>tools</code>, <code>mcp_calls</code>, <code>members</code>) must contain only strings</li> <li>invalid payloads fail with descriptive, per-field error messages</li> </ul>"},{"location":"agent-system/#3-config-file-location-and-bootstrap","title":"3) Config file location and bootstrap","text":"<p>Agent configs are stored in:</p> <ul> <li><code>Path(HALO_DATA_DIR) / \"agents\"</code></li> </ul> <p>Bootstrap/migration behavior:</p> <ol> <li>On first load, <code>migrate_agent_configs()</code> ensures default configs exist.</li> <li>A marker file <code>.migrated_v1</code> prevents repeated bootstrap.</li> <li>Defaults are generated from:</li> <li>built-in chat and pubmed defaults</li> <li>studio template definitions from <code>templates/studio_templates.json</code></li> </ol>"},{"location":"agent-system/#4-effective-config-precedence","title":"4) Effective config precedence","text":"<p>When loading agent configs:</p> <ol> <li>defaults are generated in memory (<code>_default_configs()</code>)</li> <li>on-disk JSON payload is loaded</li> <li>default + on-disk are merged (<code>defaults</code> then <code>payload</code>)</li> <li>merged config is revalidated and persisted if normalization changed values</li> </ol> <p>When applying a preset to chat:</p> <ul> <li>selected preset updates fields in <code>chat</code> config and writes back to <code>HALO_DATA_DIR/agents/chat.json</code></li> </ul>"},{"location":"agent-system/#5-agent-instruction-composition","title":"5) Agent instruction composition","text":"<p><code>build_agent_instructions(config)</code> composes final instructions from:</p> <ul> <li><code>role</code></li> <li><code>description</code></li> <li>normalized <code>instructions</code></li> <li>optional tool-use notice when tools are configured</li> </ul> <p>For Wikipedia-enabled agents, instruction text adds an explicit requirement to include clickable Wikipedia links.</p>"},{"location":"agent-system/#6-model-and-tool-factory-layer","title":"6) Model and tool factory layer","text":"<p><code>services/agent_factory.py</code> centralizes:</p>"},{"location":"agent-system/#61-model-provider-resolution","title":"6.1 Model provider resolution","text":"<p><code>normalize_model_id()</code> - normalizes plain IDs to <code>openai:&lt;id&gt;</code> unless provider already specified</p> <p><code>build_model()</code> supports: - OpenAI (<code>openai:&lt;model&gt;</code>) - optional providers when installed:   - Google Gemini   - Anthropic Claude   - Groq</p> <p>If provider dependencies or keys are missing, model creation returns <code>None</code> with warning logs.</p>"},{"location":"agent-system/#62-tool-registry","title":"6.2 Tool registry","text":"<p><code>build_tools()</code> currently supports:</p> <ul> <li><code>pubmed</code> (optionally with <code>tool_settings.pubmed</code>)</li> <li><code>wikipedia</code></li> <li><code>mermaid</code> (if optional dependency is available)</li> </ul> <p>This keeps tool construction consistent across single-agent and team paths.</p>"},{"location":"agent-system/#7-team-assembly-and-coordination","title":"7) Team assembly and coordination","text":"<p><code>services/halo_team.py::build_master_team_from_config()</code> constructs the master chat team.</p>"},{"location":"agent-system/#71-member-loading","title":"7.1 Member loading","text":"<ul> <li>member IDs come from <code>master_config.members</code></li> <li>member configs are loaded from <code>load_agent_configs()</code></li> <li>disabled members are skipped</li> <li>each member is built via <code>build_agent_from_config()</code></li> </ul>"},{"location":"agent-system/#72-coordination-modes","title":"7.2 Coordination modes","text":"<p>Selection logic is delegated to <code>services/routing_policy.py::select_member_ids()</code>.</p> <p>Supported modes:</p> <ul> <li><code>direct_only</code>: no member delegation</li> <li><code>always_delegate</code>: all configured members</li> <li><code>delegate_on_complexity</code>: keyword/skills match against prompt</li> <li><code>coordinated_rag</code>: all configured members + additional source-grounding guidance</li> <li>empty mode (<code>\"\"</code>): behaves like <code>always_delegate</code></li> </ul>"},{"location":"agent-system/#73-team-runtime-settings","title":"7.3 Team runtime settings","text":"<p>Team is instantiated with:</p> <ul> <li><code>respond_directly=True</code></li> <li><code>show_members_responses=True</code></li> <li><code>delegate_to_all_members=False</code></li> <li><code>determine_input_for_members=True</code></li> </ul> <p>Selected member IDs are attached to the team object (<code>team.selected_member_ids</code>) for traceability.</p>"},{"location":"agent-system/#8-single-agent-and-team-fallback-behavior","title":"8) Single-agent and team fallback behavior","text":"<p>Chat agent creation flow (<code>services/agents.py::build_chat_agent</code>):</p> <ol> <li>if config indicates members (or id is <code>chat</code>), attempt team creation</li> <li>if team build fails, warn and fall back to single-agent build</li> <li>if no config provided, use module-level default <code>_AGENT</code></li> </ol> <p>This preserves continuity even when optional providers/tools are unavailable.</p>"},{"location":"agent-system/#9-streaming-and-tool-event-handling","title":"9) Streaming and tool-event handling","text":"<p>Streaming is handled in <code>services/streaming_adapter.py</code> and invoked by chat runtime.</p> <p>Key behaviors:</p> <ul> <li>normalizes event names for robust matching</li> <li>deduplicates overlapping team/member content</li> <li>treats final completed events as authoritative response</li> <li>ignores post-final chunks to prevent response corruption</li> <li>captures unique tool calls and exposes them via callback</li> </ul> <p>Chat runtime passes <code>stream_events</code> from agent config so preset/config choices directly affect stream event verbosity.</p>"},{"location":"agent-system/#10-chat-turn-orchestration-and-telemetry","title":"10) Chat turn orchestration and telemetry","text":"<p><code>services/chat_runtime.py::run_chat_turn()</code> composes an execution trace containing:</p> <ul> <li>agent identity/type</li> <li>selected team members</li> <li>runtime tools</li> <li>model label</li> <li>stream mode/events/result</li> <li>latency (ms)</li> <li>knowledge hits and source names</li> <li>fallback usage flag</li> </ul> <p>Trace is attached to persisted assistant messages and rendered in UI under \"Agent Actions\".</p>"},{"location":"agent-system/#11-memory-and-knowledge-integration","title":"11) Memory and knowledge integration","text":"<p>Agents and teams may use:</p>"},{"location":"agent-system/#111-optional-db-backed-memory","title":"11.1 Optional DB-backed memory","text":"<p>From <code>services/storage.py::get_agent_db()</code>:</p> <ul> <li>enabled only when <code>HALO_AGENT_DB</code> is configured</li> <li>if unavailable or import fails, returns <code>None</code> and system remains functional</li> </ul>"},{"location":"agent-system/#112-optional-agno-knowledge-wrapper","title":"11.2 Optional Agno Knowledge wrapper","text":"<p>From <code>services/knowledge.py::get_agent_knowledge()</code>:</p> <ul> <li>initialized only when OpenAI key is available</li> <li>wraps the same LanceDB table used by retrieval</li> <li>uses vector search on Windows for stability; hybrid where feasible elsewhere</li> <li>if initialization fails, runtime falls back to manual retrieval path</li> </ul>"},{"location":"agent-system/#12-presets-and-runtime-overrides","title":"12) Presets and runtime overrides","text":"<p><code>presets.json</code> defines named chat presets.</p> <p>Preset fields currently supported:</p> <ul> <li><code>model</code></li> <li><code>tools</code></li> <li><code>members</code></li> <li><code>stream_events</code></li> <li><code>coordination_mode</code></li> </ul> <p>Applying a preset updates and persists <code>chat</code> config. This allows runtime behavior changes without code edits.</p>"},{"location":"agent-system/#13-ui-surfaces-for-agent-management","title":"13) UI surfaces for agent management","text":"<p>Two configuration surfaces exist:</p> <ol> <li>Sidebar panel in <code>app/main.py</code> (<code>_render_configuration_panel</code>)</li> <li>Dedicated page <code>app/pages/Agent_Config.py</code></li> </ol> <p>Capabilities include:</p> <ul> <li>selecting/editing agents</li> <li>enabling/disabling agents</li> <li>changing instructions/skills/tools/MCP calls</li> <li>adjusting model and coordination mode</li> <li>toggling stream events</li> </ul>"},{"location":"agent-system/#14-adding-a-new-agent-recommended-path","title":"14) Adding a new agent (recommended path)","text":"<ol> <li>Create <code>HALO_DATA_DIR/agents/&lt;agent_id&gt;.json</code> with schema-compliant payload.</li> <li>Set <code>enabled: true</code>.</li> <li>Optionally add <code>skills</code> for routing in <code>delegate_on_complexity</code> mode.</li> <li>Add agent ID to chat <code>members</code> in config page or preset.</li> <li>If needed, add supported tool ID and tool settings.</li> <li>Validate behavior in chat with relevant coordination mode.</li> </ol>"},{"location":"agent-system/#15-common-troubleshooting","title":"15) Common troubleshooting","text":""},{"location":"agent-system/#team-not-delegating-as-expected","title":"Team not delegating as expected","text":"<ul> <li>Verify <code>coordination_mode</code> value</li> <li>In <code>delegate_on_complexity</code>, ensure prompt contains skill tags expected by member configs</li> <li>Confirm member agents are enabled</li> </ul>"},{"location":"agent-system/#model-does-not-run","title":"Model does not run","text":"<ul> <li>confirm provider prefix in model ID (e.g. <code>openai:gpt-5.2</code>)</li> <li>confirm required API key/dependency is available for that provider</li> </ul>"},{"location":"agent-system/#tool-call-events-missing","title":"Tool call events missing","text":"<ul> <li>ensure config/preset sets <code>stream_events: true</code></li> <li>inspect \"Tool Calls\" and \"Agent Actions\" in chat UI</li> </ul>"},{"location":"agent-system/#agent-memory-not-persistent","title":"Agent memory not persistent","text":"<ul> <li>set <code>HALO_AGENT_DB</code> to a valid sqlite path</li> <li>check logs for DB initialization warnings</li> </ul>"},{"location":"agent-system/#16-governance-notes","title":"16) Governance notes","text":"<p>The current architecture intentionally keeps:</p> <ul> <li>behavior/config in service modules and JSON</li> <li>UI layer thin on orchestration logic</li> <li>deterministic, test-covered routing/stream handling</li> </ul> <p>This supports incremental hardening while preserving existing app behavior.</p>"},{"location":"architecture-and-runtime/","title":"HALO Core Architecture and Runtime Flows","text":""},{"location":"architecture-and-runtime/#1-architectural-style","title":"1) Architectural style","text":"<p>HALO Core follows a UI + service-layer split:</p> <ul> <li><code>app/</code> handles Streamlit rendering and interaction wiring.</li> <li><code>services/</code> handles orchestration, storage, ingestion, retrieval, routing, and agent behavior.</li> </ul> <p>The current codebase is in an incremental migration state: some runtime logic still lives in <code>app/main.py</code>, while core chat orchestration has already been extracted into <code>services/chat_runtime.py</code>.</p>"},{"location":"architecture-and-runtime/#2-runtime-layers","title":"2) Runtime layers","text":""},{"location":"architecture-and-runtime/#21-presentation-layer","title":"2.1 Presentation layer","text":"<ul> <li><code>app/main.py</code>: primary 3-panel UI and sidebar</li> <li><code>app/pages/*.py</code>: auxiliary Streamlit pages (Configuration, Agent Config, Dashboard, Account, Help)</li> </ul>"},{"location":"architecture-and-runtime/#22-orchestration-layer","title":"2.2 Orchestration layer","text":"<ul> <li><code>services/chat_runtime.py</code>: chat-turn pipeline (payload, agent creation, stream handling, fallback, trace)</li> <li><code>services/pipelines.py</code>: lightweight wrappers for chat/studio/infographic generation</li> <li><code>services/agents.py</code>: core agent and team invocation logic</li> </ul>"},{"location":"architecture-and-runtime/#23-agentteam-coordination-layer","title":"2.3 Agent/team coordination layer","text":"<ul> <li><code>services/halo_team.py</code>: team assembly from config</li> <li><code>services/routing_policy.py</code>: deterministic member selection for coordination modes</li> <li><code>services/agent_factory.py</code>: provider/model/tool factory functions</li> <li><code>services/agents_config.py</code>: config schema, defaults, migration, persistence</li> <li><code>services/presets.py</code>: preset application and chat config overrides</li> </ul>"},{"location":"architecture-and-runtime/#24-data-and-retrieval-layer","title":"2.4 Data and retrieval layer","text":"<ul> <li><code>services/storage.py</code>: JSON persistence and optional agent DB initialization</li> <li><code>services/ingestion.py</code>: source extraction + indexing bridge</li> <li><code>services/parsers.py</code>: file-type-specific parsing/transcription/captioning</li> <li><code>services/chunking.py</code>: text normalization/chunk segmentation</li> <li><code>services/retrieval.py</code>: LanceDB indexing and similarity search</li> <li><code>services/knowledge.py</code>: optional native Agno Knowledge wrapper over LanceDB</li> </ul>"},{"location":"architecture-and-runtime/#25-streaming-abstraction-layer","title":"2.5 Streaming abstraction layer","text":"<ul> <li><code>services/streaming_adapter.py</code>: normalizes event names, deduplicates output, merges tool events, and enforces final response authority.</li> </ul>"},{"location":"architecture-and-runtime/#3-app-startup-flow","title":"3) App startup flow","text":"<ol> <li><code>run_app()</code> sets page configuration and renders sidebar.</li> <li><code>_init_state()</code> initializes session-state keys and loads persisted data:</li> <li>session id</li> <li>sources</li> <li>chat history</li> <li>notes</li> <li>studio templates and outputs</li> <li>app config</li> <li>agent configs</li> <li>Main content is rendered via three Streamlit columns:</li> <li><code>render_sources_panel()</code></li> <li><code>render_chat_panel()</code></li> <li><code>render_studio_panel()</code></li> </ol>"},{"location":"architecture-and-runtime/#4-source-ingestion-flow","title":"4) Source ingestion flow","text":""},{"location":"architecture-and-runtime/#41-upload-and-document-parsing","title":"4.1 Upload and document parsing","text":"<p>In Sources panel:</p> <ul> <li>user uploads one or more files</li> <li>each file is passed to <code>ingestion.extract_document_payload()</code></li> <li>extraction delegates to <code>parsers.extract_text_from_bytes()</code></li> <li>a source entry is created and persisted in JSON</li> <li>parsed body is chunked and indexed into LanceDB via <code>ingestion.ingest_source_content()</code> and <code>retrieval.index_source_text()</code></li> </ul>"},{"location":"architecture-and-runtime/#42-supported-content-paths","title":"4.2 Supported content paths","text":"<p>Parser behavior by extension:</p> <ul> <li>text-like: <code>.txt</code>, <code>.md</code>, <code>.csv</code></li> <li>office docs: <code>.pdf</code>, <code>.docx</code>, <code>.xlsx</code>, <code>.pptx</code></li> <li>image captioning path (if API key available): <code>.png</code>, <code>.jpg</code>, <code>.jpeg</code>, <code>.webp</code>, <code>.gif</code></li> <li>audio transcription path: <code>.mp3</code>, <code>.wav</code>, <code>.m4a</code>, <code>.aac</code>, <code>.flac</code>, <code>.ogg</code>, <code>.opus</code></li> <li>video transcription path: <code>.mp4</code>, <code>.mov</code>, <code>.mkv</code>, <code>.webm</code>, <code>.avi</code></li> </ul>"},{"location":"architecture-and-runtime/#43-connector-and-web-search-paths","title":"4.3 Connector and web search paths","text":"<ul> <li>connectors are currently mock providers (<code>GoogleDriveConnector</code>, <code>NotionConnector</code>) cached in JSON</li> <li>web search in ingestion is currently a mock response set</li> </ul>"},{"location":"architecture-and-runtime/#5-chat-turn-flow","title":"5) Chat turn flow","text":"<p>Chat flow is intentionally split between UI and service orchestration.</p>"},{"location":"architecture-and-runtime/#51-ui-responsibilities-render_chat_panel","title":"5.1 UI responsibilities (<code>render_chat_panel</code>)","text":"<ul> <li>render chat history and media attachments</li> <li>capture user input from <code>st.chat_input</code> (text, optional images, optional audio)</li> <li>persist user message</li> <li>create <code>ChatTurnInput</code></li> <li>wire UI callbacks for streaming response and tool-call display</li> <li>append final assistant message to persisted history</li> </ul>"},{"location":"architecture-and-runtime/#52-runtime-responsibilities-serviceschat_runtimepy","title":"5.2 Runtime responsibilities (<code>services/chat_runtime.py</code>)","text":"<p><code>run_chat_turn()</code> pipeline:</p> <ol> <li><code>build_chat_payload()</code></li> <li>query retrieval contexts (<code>retrieval.query_similar</code>)</li> <li>build payload text (<code>agents.build_chat_payload</code>)</li> <li><code>create_chat_agent()</code></li> <li>build team/agent from config (with prompt-aware fallback)</li> <li><code>stream_chat_response()</code></li> <li>stream normalized events via <code>stream_agent_response</code></li> <li>response handling</li> <li>if stream is <code>None</code> or empty: fallback to <code>pipelines.generate_chat_reply</code></li> <li>apply citation policy</li> <li>trace and telemetry</li> <li>compose structured trace with model, members, tools, latency, knowledge hits/sources, stream outcome</li> </ol>"},{"location":"architecture-and-runtime/#6-streaming-behavior-model","title":"6) Streaming behavior model","text":"<p><code>stream_agent_response()</code> handles difficult stream cases:</p> <ul> <li>normalizes event names across possible event enum/string formats</li> <li>allows content only for known run/team events</li> <li>deduplicates team/member output overlap</li> <li>treats completed events as authoritative final output</li> <li>ignores post-final chunks to avoid corrupted response merges</li> <li>collects tool-call events into unique tool list</li> </ul> <p>This behavior is validated by streaming-focused tests in <code>tests/test_streaming.py</code> and runtime tests in <code>tests/test_chat_runtime.py</code>.</p>"},{"location":"architecture-and-runtime/#7-citation-and-grounding-policy","title":"7) Citation and grounding policy","text":"<p>Chat runtime applies a post-processing citation policy:</p> <ul> <li>single source: append one normalized citation (<code>[Quelle: ...]</code> + page when available)</li> <li>multiple sources: append a markdown <code>### Quellen</code> section with bulletized citations</li> <li>existing citation tags are cleaned/reduced for consistency</li> </ul> <p>Page inference supports multiple metadata key names (<code>page</code>, <code>page_number</code>, <code>page_index</code>, <code>chunk_index</code>, etc.).</p>"},{"location":"architecture-and-runtime/#8-studio-generation-flow","title":"8) Studio generation flow","text":"<p><code>render_studio_panel()</code> loads templates from <code>templates/studio_templates.json</code> and renders cards.</p> <p>Card generation flow:</p> <ol> <li>user presses template generate action</li> <li>UI builds prompt from language/tone/instructions/user prompt</li> <li>selected sources are passed to pipeline</li> <li>for infographic template, dedicated image generation pipeline is used</li> <li>output is normalized and persisted to <code>studio_outputs</code></li> <li>output appears in Studio results section, where it can be:</li> <li>renamed</li> <li>downloaded</li> <li>deleted</li> <li>promoted to source</li> </ol> <p>Studio notes are managed separately in <code>studio_notes</code> and can also be promoted to source entries.</p>"},{"location":"architecture-and-runtime/#9-persistence-architecture","title":"9) Persistence architecture","text":"<p>Persistence uses local files by default, under <code>HALO_DATA_DIR</code>:</p> <ul> <li>source catalog</li> <li>notes and studio outputs</li> <li>connector cache</li> <li>per-session chat history JSON files</li> <li>LanceDB vector store for retrieval</li> </ul> <p>Optional persistent Agno DB memory is activated when <code>HALO_AGENT_DB</code> is configured.</p>"},{"location":"architecture-and-runtime/#10-config-driven-behavior","title":"10) Config-driven behavior","text":"<p>Configuration is data-driven in three major areas:</p> <ol> <li>Agent configs (<code>data/agents/*.json</code>)</li> <li>Studio template definitions (<code>templates/studio_templates.json</code>)</li> <li>Chat presets (<code>presets.json</code>)</li> </ol> <p>This allows many behavior changes without touching Python code.</p>"},{"location":"architecture-and-runtime/#11-fallback-and-resilience-behavior","title":"11) Fallback and resilience behavior","text":"<p>The implementation includes multiple protective fallback paths:</p> <ul> <li>model construction returns <code>None</code> if provider/key unavailable</li> <li>team build falls back to single-agent mode</li> <li>stream failure or empty stream falls back to non-streaming generation</li> <li>parser functions return meaningful placeholders when API keys are absent for media understanding</li> <li>knowledge initialization failures degrade to manual retrieval path</li> </ul>"},{"location":"architecture-and-runtime/#12-observability-and-trace-model","title":"12) Observability and trace model","text":"<p>Runtime traces combine base agent trace and chat telemetry envelope:</p> <ul> <li>model</li> <li>selected members</li> <li>tools</li> <li>stream mode/events/result</li> <li>latency (ms)</li> <li>knowledge hits and source names</li> <li>fallback usage flag</li> </ul> <p>Traces are attached to assistant chat messages and rendered in UI under \"Agent Actions\".</p>"},{"location":"architecture-and-runtime/#13-architectural-constraints-and-near-term-priorities","title":"13) Architectural constraints and near-term priorities","text":"<p>Current constraints:</p> <ul> <li><code>app/main.py</code> remains large and still contains mixed concerns</li> <li>some connectors and search paths are mock/demo behavior</li> <li>studio export helpers are placeholder-level for PDF/slide output</li> </ul> <p>Near-term direction (as already tracked in backlog/docs):</p> <ul> <li>continue extracting orchestration from <code>app/main.py</code></li> <li>keep routing and stream handling deterministic and test-covered</li> <li>expand native Agno knowledge/memory usage while preserving safe fallback behavior</li> </ul>"},{"location":"data-storage-and-retrieval/","title":"HALO Core Data Storage, Ingestion, and Retrieval","text":""},{"location":"data-storage-and-retrieval/#1-storage-model-summary","title":"1) Storage model summary","text":"<p>HALO Core persists most runtime state in local JSON files plus LanceDB vectors.</p> <p>Base location is <code>HALO_DATA_DIR</code> (default: <code>data/</code>).</p> <p>Primary persisted assets:</p> <ul> <li><code>sources.json</code></li> <li><code>studio_notes.json</code></li> <li><code>studio_outputs.json</code></li> <li><code>config.json</code></li> <li><code>connector_cache.json</code></li> <li><code>chat_history/&lt;session_id&gt;.json</code></li> <li><code>lancedb/</code> vector store</li> </ul> <p>Optional: Agno memory DB via <code>HALO_AGENT_DB</code>.</p>"},{"location":"data-storage-and-retrieval/#2-json-persistence-layer-servicesstoragepy","title":"2) JSON persistence layer (<code>services/storage.py</code>)","text":"<p><code>services/storage.py</code> provides read/write helpers and ensures data directories exist.</p>"},{"location":"data-storage-and-retrieval/#21-sources","title":"2.1 Sources","text":"<ul> <li>load: <code>load_sources()</code></li> <li>save: <code>save_sources(sources)</code></li> </ul> <p>Used by source panel for displaying and maintaining selected source inventory.</p>"},{"location":"data-storage-and-retrieval/#22-studio-notes-and-outputs","title":"2.2 Studio notes and outputs","text":"<ul> <li>notes: <code>load_notes()</code> / <code>save_notes()</code></li> <li>outputs: <code>load_studio_outputs()</code> / <code>save_studio_outputs()</code></li> </ul> <p>Studio output and note actions (rename, delete, promote, download) operate on these JSON-backed structures.</p>"},{"location":"data-storage-and-retrieval/#23-chat-history","title":"2.3 Chat history","text":"<ul> <li>load: <code>load_chat_history(session_id)</code></li> <li>save: <code>save_chat_history(session_id, history)</code></li> </ul> <p>Each chat session has its own JSON file under <code>chat_history/</code>.</p>"},{"location":"data-storage-and-retrieval/#24-ui-config-and-connector-cache","title":"2.4 UI config and connector cache","text":"<ul> <li>config: <code>load_config()</code> / <code>save_config()</code></li> <li>connector cache: <code>load_connector_cache()</code> / <code>save_connector_cache()</code></li> </ul> <p>Connector cache avoids unnecessary repeated fetches in non-refresh paths.</p>"},{"location":"data-storage-and-retrieval/#3-source-ingestion-pipeline","title":"3) Source ingestion pipeline","text":"<p>The ingestion path is orchestrated by <code>services/ingestion.py</code>.</p>"},{"location":"data-storage-and-retrieval/#31-upload-payload-extraction","title":"3.1 Upload payload extraction","text":"<p><code>extract_document_payload(filename, data)</code> returns:</p> <ul> <li><code>title</code></li> <li><code>type_label</code></li> <li><code>body</code></li> </ul> <p><code>type_label</code> is inferred from extension via <code>infer_type_label()</code>.</p>"},{"location":"data-storage-and-retrieval/#32-indexing-flow","title":"3.2 Indexing flow","text":"<p><code>ingest_source_content(title, body, meta)</code>:</p> <ol> <li>calls <code>chunking.prepare_chunks(...)</code></li> <li>iterates chunk records</li> <li>indexes each into retrieval with <code>retrieval.index_source_text(...)</code></li> </ol>"},{"location":"data-storage-and-retrieval/#33-directory-ingestion-helper","title":"3.3 Directory ingestion helper","text":"<p><code>load_directory_documents(directory)</code> recursively loads supported textual documents (excluding image/audio/video media paths).</p>"},{"location":"data-storage-and-retrieval/#4-parser-system-servicesparserspy","title":"4) Parser system (<code>services/parsers.py</code>)","text":"<p><code>extract_text_from_bytes()</code> routes by extension.</p>"},{"location":"data-storage-and-retrieval/#41-text-and-office-formats","title":"4.1 Text and office formats","text":"<ul> <li>text-like: direct decoding with utf-8/latin-1 fallback</li> <li>PDF: <code>pypdf.PdfReader</code></li> <li>DOCX: <code>python-docx</code></li> <li>CSV/XLSX/PPTX: Agno knowledge readers</li> </ul>"},{"location":"data-storage-and-retrieval/#42-image-parsing-path","title":"4.2 Image parsing path","text":"<ul> <li>if OpenAI key exists: image caption agent (<code>gpt-4o-mini</code>) describes image</li> <li>otherwise fallback text: <code>\"Bilddatei: &lt;filename&gt;\"</code></li> </ul>"},{"location":"data-storage-and-retrieval/#43-audio-parsing-path","title":"4.3 Audio parsing path","text":"<ul> <li>if OpenAI key exists: OpenAI transcription via <code>OpenAITools</code></li> <li>otherwise fallback text: <code>\"Audio-Datei: &lt;filename&gt;\"</code></li> </ul>"},{"location":"data-storage-and-retrieval/#44-video-parsing-path","title":"4.4 Video parsing path","text":"<ul> <li>extracts audio with <code>MoviePyVideoTools</code></li> <li>transcribes extracted audio via OpenAI tools</li> <li>falls back to placeholder text when key unavailable</li> </ul>"},{"location":"data-storage-and-retrieval/#5-chunking-logic-serviceschunkingpy","title":"5) Chunking logic (<code>services/chunking.py</code>)","text":"<p>Core constants:</p> <ul> <li><code>DEFAULT_CHUNK_SIZE = 500</code></li> <li><code>DEFAULT_CHUNK_OVERLAP = 75</code></li> </ul> <p>Pipeline:</p> <ol> <li>normalize whitespace (<code>normalize_text</code>)</li> <li>split into overlapping word windows (<code>chunk_text</code>)</li> <li>enrich each chunk with metadata (<code>prepare_chunks</code>)</li> </ol> <p>Metadata includes:</p> <ul> <li><code>source_title</code></li> <li><code>type_label</code></li> <li><code>chunk_index</code></li> <li><code>chunk_count</code></li> <li>any additional source metadata</li> </ul>"},{"location":"data-storage-and-retrieval/#6-vector-indexing-and-retrieval-servicesretrievalpy","title":"6) Vector indexing and retrieval (<code>services/retrieval.py</code>)","text":""},{"location":"data-storage-and-retrieval/#61-database-structure","title":"6.1 Database structure","text":"<ul> <li>LanceDB path: <code>&lt;HALO_DATA_DIR&gt;/lancedb</code></li> <li>table name: <code>sources</code></li> </ul> <p>Each record stores:</p> <ul> <li><code>text</code></li> <li><code>embedding</code></li> <li><code>meta</code> (includes <code>title</code> and source metadata)</li> </ul>"},{"location":"data-storage-and-retrieval/#62-embedding-behavior","title":"6.2 Embedding behavior","text":"<p><code>_embed(text)</code>:</p> <ul> <li>with OpenAI key: uses <code>text-embedding-3-small</code></li> <li>without key: deterministic random embedding fallback (hash-seeded)</li> </ul> <p>This allows local/offline behavior while preserving deterministic retrieval tests.</p>"},{"location":"data-storage-and-retrieval/#63-query-path","title":"6.3 Query path","text":"<p><code>query_similar(text, limit=5)</code>:</p> <ul> <li>computes query embedding</li> <li>cosine similarity search in LanceDB</li> <li>returns top matches with metadata</li> </ul>"},{"location":"data-storage-and-retrieval/#64-source-maintenance-operations","title":"6.4 Source maintenance operations","text":"<ul> <li><code>delete_source_chunks(source_id, title=None)</code>:</li> <li>delete by <code>meta.source_id</code></li> <li> <p>fallback to <code>meta.title</code> when older rows lack source id</p> </li> <li> <p><code>rename_source(source_id, new_title, previous_title=None)</code>:</p> </li> <li>preferred path uses LanceDB update by source id</li> <li>fallback path rebuilds affected rows when needed</li> </ul>"},{"location":"data-storage-and-retrieval/#7-knowledge-abstraction-servicesknowledgepy","title":"7) Knowledge abstraction (<code>services/knowledge.py</code>)","text":"<p><code>get_agent_knowledge()</code> wraps LanceDB with native Agno Knowledge when possible.</p> <p>Key behavior:</p> <ul> <li>requires OpenAI API key</li> <li>reuses same database/table as retrieval (<code>lancedb/sources</code>)</li> <li>on Windows, prefers vector search for stability over hybrid index mutation behavior</li> <li>if initialization fails, returns <code>None</code> and app falls back to manual retrieval</li> </ul>"},{"location":"data-storage-and-retrieval/#8-source-lifecycle-end-to-end","title":"8) Source lifecycle end-to-end","text":"<ol> <li>Source added in UI (upload/search/connector/note/studio output)</li> <li>Source metadata persisted in <code>sources.json</code></li> <li>Source body (if available) chunked and indexed in LanceDB</li> <li>Chat retrieval queries top chunks for each prompt</li> <li>Citation policy appends source references into final assistant response</li> </ol>"},{"location":"data-storage-and-retrieval/#9-chat-persistence-lifecycle","title":"9) Chat persistence lifecycle","text":"<ol> <li>Session ID initialized in app state</li> <li>existing <code>chat_history/&lt;session&gt;.json</code> loaded (or welcome message used)</li> <li>every appended message persisted to session history JSON</li> <li>assistant messages may include:</li> <li>serialized tool calls</li> <li>structured trace/telemetry</li> <li>image references</li> </ol> <p>This allows full chat restoration on rerun.</p>"},{"location":"data-storage-and-retrieval/#10-studio-and-notes-lifecycle","title":"10) Studio and notes lifecycle","text":""},{"location":"data-storage-and-retrieval/#101-studio-outputs","title":"10.1 Studio outputs","text":"<p>Generated output payload is normalized to include:</p> <ul> <li><code>content</code></li> <li><code>sources</code></li> <li><code>generated_at</code></li> <li>optional <code>image_path</code></li> </ul> <p>Persisted to <code>studio_outputs.json</code> and displayed in ordered section.</p>"},{"location":"data-storage-and-retrieval/#102-notes","title":"10.2 Notes","text":"<p>Notes can come from:</p> <ul> <li>chat response \"save to note\"</li> <li>all-sources summary pin</li> <li>manual note add dialog</li> </ul> <p>Persisted in <code>studio_notes.json</code>, with actions for rename/delete/download/promote to source.</p>"},{"location":"data-storage-and-retrieval/#11-connector-data-flow","title":"11) Connector data flow","text":"<p>Current connectors are mock abstractions in <code>services/connectors.py</code>.</p> <p>Flow:</p> <ol> <li>user selects connector slugs</li> <li>cached results returned unless refresh requested</li> <li>otherwise connector fetch runs and cache is updated</li> <li>selected entries can be promoted into source list</li> </ol> <p>Connector cache format is JSON and stored in <code>connector_cache.json</code>.</p>"},{"location":"data-storage-and-retrieval/#12-operational-considerations","title":"12) Operational considerations","text":""},{"location":"data-storage-and-retrieval/#121-local-data-location","title":"12.1 Local data location","text":"<p>Use <code>HALO_DATA_DIR</code> to isolate data per environment (dev/test/staging).</p>"},{"location":"data-storage-and-retrieval/#122-secret-handling","title":"12.2 Secret handling","text":"<ul> <li>keep API keys in <code>.streamlit/secrets.toml</code> or environment variables</li> <li>do not commit secrets</li> </ul>"},{"location":"data-storage-and-retrieval/#123-onedrivewindows-considerations","title":"12.3 OneDrive/Windows considerations","text":"<p>Repository and data paths under OneDrive can affect file locking/index operations.</p> <p>Current mitigations include:</p> <ul> <li>safe temp-file cleanup retries in parsers</li> <li>vector search fallback in knowledge module on Windows</li> </ul>"},{"location":"data-storage-and-retrieval/#13-backup-and-cleanup-guidance","title":"13) Backup and cleanup guidance","text":"<p>Recommended for operators:</p> <ol> <li>Back up JSON files + <code>lancedb/</code> together.</li> <li>Keep session history files if auditability matters.</li> <li>If rebuilding index, keep <code>sources.json</code> and re-run ingestion/indexing path.</li> <li>Validate retrieval quality after any index migration.</li> </ol>"},{"location":"data-storage-and-retrieval/#14-known-limitations","title":"14) Known limitations","text":"<ul> <li>Connector/web search are currently mock implementations.</li> <li>Embedding fallback without OpenAI key is deterministic but not semantically meaningful.</li> <li>Studio export formats beyond markdown are placeholder-quality in current implementation.</li> </ul> <p>These are active areas for progressive hardening as tracked in backlog and internal PRDs.</p>"},{"location":"development-testing-and-operations/","title":"HALO Core Development, Testing, and Operations","text":""},{"location":"development-testing-and-operations/#1-prerequisites","title":"1) Prerequisites","text":"<p>Minimum local requirements:</p> <ul> <li>Python 3.10+</li> <li>Git</li> <li>FFmpeg (required for audio/video parsing paths)</li> <li>API credentials for model/tool providers (at least OpenAI for full functionality)</li> </ul> <p>Repository dependencies are defined in <code>requirements.txt</code>.</p>"},{"location":"development-testing-and-operations/#2-local-setup","title":"2) Local setup","text":""},{"location":"development-testing-and-operations/#21-environment-setup","title":"2.1 Environment setup","text":"<pre><code>python -m venv .venv\n. .venv/Scripts/activate\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre>"},{"location":"development-testing-and-operations/#22-secrets-and-configuration","title":"2.2 Secrets and configuration","text":"<p>Use <code>.streamlit/secrets.toml</code> and/or environment variables.</p> <p>Important settings consumed by <code>services/settings.py</code>:</p> <ul> <li><code>OPENAI_API_KEY</code></li> <li><code>HALO_DATA_DIR</code></li> <li><code>HALO_TEMPLATES_DIR</code></li> <li><code>HALO_AGENT_DB</code></li> </ul> <p>Do not hardcode secrets in source files.</p>"},{"location":"development-testing-and-operations/#23-running-the-app","title":"2.3 Running the app","text":"<pre><code>streamlit run app/main.py\n</code></pre>"},{"location":"development-testing-and-operations/#3-daily-development-workflow","title":"3) Daily development workflow","text":"<p>Recommended loop:</p> <ol> <li>Pull latest changes and inspect current docs/PRDs if feature scope changed.</li> <li>Implement focused changes in relevant module.</li> <li>Run targeted tests for touched services first.</li> <li>Run lint/format checks.</li> <li>Run full test suite before finalizing.</li> </ol>"},{"location":"development-testing-and-operations/#4-testing-strategy","title":"4) Testing strategy","text":"<p>The repository uses pytest with module-focused tests under <code>tests/</code>.</p> <p>High-value test areas include:</p> <ul> <li><code>test_chat_runtime.py</code>: chat orchestration + telemetry + fallback behavior</li> <li><code>test_streaming.py</code>: stream event dedup/final-response correctness</li> <li><code>test_agents_config.py</code>: schema and config merge logic</li> <li><code>test_halo_team.py</code>: team routing/coordination behavior</li> <li><code>test_chat_state.py</code>: message/state helper behavior</li> <li><code>test_chunking.py</code>, <code>test_ingestion.py</code>, <code>test_knowledge.py</code>: ingestion/retrieval support paths</li> </ul> <p>Run all tests:</p> <pre><code>pytest\n</code></pre> <p>Run targeted tests:</p> <pre><code>pytest tests/test_chat_runtime.py -v\npytest tests/test_streaming.py -v\n</code></pre>"},{"location":"development-testing-and-operations/#5-linting-and-formatting","title":"5) Linting and formatting","text":"<p>Standard tools in repository workflows:</p> <ul> <li><code>ruff check .</code></li> <li><code>black --check .</code></li> <li><code>mypy app services</code> (configured in docs, currently commented in CI)</li> </ul> <p>Typical local sequence:</p> <pre><code>ruff check .\nblack --check .\n</code></pre> <p>If formatting fixes are needed:</p> <pre><code>black .\n</code></pre>"},{"location":"development-testing-and-operations/#6-cicd-workflows","title":"6) CI/CD workflows","text":"<p>Defined under <code>.github/workflows/</code>.</p>"},{"location":"development-testing-and-operations/#61-ci-ciyml","title":"6.1 CI (<code>ci.yml</code>)","text":"<ul> <li>triggers on push to main and pull requests</li> <li>runs on Python 3.11 and 3.13</li> <li>installs dependencies and quality tooling</li> <li>runs:</li> <li>ruff</li> <li>black check</li> <li>pytest</li> </ul>"},{"location":"development-testing-and-operations/#62-docs-lint-docsyml","title":"6.2 Docs lint (<code>docs.yml</code>)","text":"<ul> <li>triggers on PRs touching markdown files</li> <li>runs markdown lint over <code>**/*.md</code></li> </ul>"},{"location":"development-testing-and-operations/#63-dependency-audit-audityml","title":"6.3 Dependency audit (<code>audit.yml</code>)","text":"<ul> <li>scheduled weekly + manual dispatch</li> <li>runs <code>pip-audit -r requirements.txt</code></li> </ul>"},{"location":"development-testing-and-operations/#64-release-build-releaseyml","title":"6.4 Release build (<code>release.yml</code>)","text":"<ul> <li>triggers on version tag pushes (<code>v*</code>)</li> <li>builds Docker image and emits summary</li> </ul>"},{"location":"development-testing-and-operations/#7-runtime-observability-and-debugging","title":"7) Runtime observability and debugging","text":""},{"location":"development-testing-and-operations/#71-logging-controls","title":"7.1 Logging controls","text":"<p>App configuration supports toggles for:</p> <ul> <li>agent payload logs</li> <li>agent response logs</li> <li>agent error logs</li> <li>user request logs</li> <li>stream event logs</li> </ul> <p>These are configured in UI and persisted in <code>config.json</code>.</p>"},{"location":"development-testing-and-operations/#72-chat-run-traces","title":"7.2 Chat run traces","text":"<p>Assistant messages can include structured traces with telemetry fields:</p> <ul> <li>model</li> <li>selected members</li> <li>tools</li> <li>stream outcome</li> <li>latency</li> <li>knowledge hits/sources</li> <li>fallback usage</li> </ul> <p>This enables rapid diagnosis of routing, stream, and grounding behavior.</p>"},{"location":"development-testing-and-operations/#8-common-troubleshooting","title":"8) Common troubleshooting","text":""},{"location":"development-testing-and-operations/#81-app-starts-but-chat-responses-are-poorplaceholder","title":"8.1 App starts but chat responses are poor/placeholder","text":"<p>Likely cause: - missing OpenAI key</p> <p>Actions: 1. confirm <code>OPENAI_API_KEY</code> exists in secrets/env 2. restart streamlit session 3. verify model id in chat config/preset</p>"},{"location":"development-testing-and-operations/#82-team-members-not-active","title":"8.2 Team members not active","text":"<p>Likely causes: - members disabled in agent config - coordination mode set to <code>direct_only</code> - prompt did not match <code>skills</code> for <code>delegate_on_complexity</code></p> <p>Actions: 1. open Agent Config page 2. verify member <code>enabled</code>, <code>skills</code>, <code>coordination_mode</code> 3. inspect assistant trace in \"Agent Actions\"</p>"},{"location":"development-testing-and-operations/#83-tool-calls-not-displayed","title":"8.3 Tool calls not displayed","text":"<p>Likely causes: - <code>stream_events</code> disabled in agent/preset - tools not configured for active agent/member</p> <p>Actions: 1. verify <code>stream_events: true</code> 2. verify tool IDs in config 3. enable stream debug logging</p>"},{"location":"development-testing-and-operations/#84-media-parsing-issues","title":"8.4 Media parsing issues","text":"<p>Likely causes: - missing FFmpeg or API keys</p> <p>Actions: 1. verify FFmpeg in PATH 2. verify OpenAI key for transcription/caption paths 3. check parser error output in UI/logs</p>"},{"location":"development-testing-and-operations/#9-data-and-environment-operations","title":"9) Data and environment operations","text":""},{"location":"development-testing-and-operations/#91-data-directory-control","title":"9.1 Data directory control","text":"<p>Use <code>HALO_DATA_DIR</code> to separate datasets by environment.</p> <p>Suggested structure:</p> <ul> <li><code>data-dev/</code></li> <li><code>data-staging/</code></li> <li><code>data-prod/</code> (if applicable)</li> </ul>"},{"location":"development-testing-and-operations/#92-optional-agent-db-memory","title":"9.2 Optional agent DB memory","text":"<p>Set <code>HALO_AGENT_DB</code> to enable persistent Agno memory backend.</p> <p>If unset, app runs in JSON-only memory mode without failure.</p>"},{"location":"development-testing-and-operations/#93-backup-recommendations","title":"9.3 Backup recommendations","text":"<p>Back up together:</p> <ul> <li>JSON files in data dir</li> <li><code>chat_history/</code></li> <li><code>lancedb/</code></li> <li><code>agents/</code> config folder</li> </ul>"},{"location":"development-testing-and-operations/#10-contribution-and-quality-expectations","title":"10) Contribution and quality expectations","text":"<p>Project documentation and standards emphasize:</p> <ul> <li>focused, minimal diffs</li> <li>behavior-preserving refactors unless explicitly changing behavior</li> <li>tests updated with behavior changes</li> <li>docs updated when architecture/runtime changes</li> </ul> <p>Primary references:</p> <ul> <li><code>AGENTS.md</code></li> <li><code>CONTRIBUTING.md</code></li> <li><code>README.md</code></li> </ul>"},{"location":"development-testing-and-operations/#11-suggested-change-playbooks","title":"11) Suggested change playbooks","text":""},{"location":"development-testing-and-operations/#111-chatruntime-change","title":"11.1 Chat/runtime change","text":"<ol> <li>update service logic (<code>chat_runtime</code>, <code>streaming_adapter</code>, <code>agents</code>, or <code>halo_team</code>)</li> <li>add/update focused tests</li> <li>run chat/runtime + streaming tests</li> <li>run full test suite</li> <li>update docs in <code>docs/</code> if behavior changed</li> </ol>"},{"location":"development-testing-and-operations/#112-ingestionretrieval-change","title":"11.2 Ingestion/retrieval change","text":"<ol> <li>update <code>parsers</code>/<code>ingestion</code>/<code>chunking</code>/<code>retrieval</code></li> <li>add/update ingestion/chunking/retrieval tests</li> <li>verify source add/index/query path manually</li> <li>document any schema/data migration implications</li> </ol>"},{"location":"development-testing-and-operations/#113-ui-panel-change","title":"11.3 UI panel change","text":"<ol> <li>keep rendering concerns in <code>app/</code></li> <li>avoid embedding new business logic in panel functions when service abstraction exists</li> <li>validate all panel actions still persist state correctly</li> <li>include screenshots/notes in PR when UX behavior changes</li> </ol>"},{"location":"development-testing-and-operations/#12-release-readiness-checklist","title":"12) Release readiness checklist","text":"<p>Before tagging a release candidate:</p> <ol> <li>All CI checks passing (lint/format/tests)</li> <li>No known blocking regressions in chat/source/studio flows</li> <li>Docs reflect current runtime behavior</li> <li>Agent config defaults and templates are valid</li> <li>Dependency audit findings reviewed</li> </ol> <p>This checklist should be treated as minimum quality gate for stable delivery.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11+</li> <li>A virtual environment (<code>.venv</code>)</li> </ul>"},{"location":"getting-started/#install","title":"Install","text":"<pre><code>python -m venv .venv\n.venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#run-the-app","title":"Run the app","text":"<pre><code>streamlit run app/main.py\n</code></pre>"},{"location":"getting-started/#run-quality-checks","title":"Run quality checks","text":"<pre><code>black .\nruff check .\npytest\n</code></pre>"},{"location":"getting-started/#next-reading","title":"Next reading","text":"<ul> <li>Repository Overview</li> <li>Architecture and Runtime</li> </ul>"},{"location":"repository-overview/","title":"HALO Core Repository Overview","text":""},{"location":"repository-overview/#1-purpose","title":"1) Purpose","text":"<p>HALO Core is a Streamlit-based, NotebookLM-style workspace that combines:</p> <ul> <li>Source management (\"Quellen\")</li> <li>Grounded chat over selected sources</li> <li>Studio-style artifact generation (reports, infographic, podcast, presentation, table, etc.)</li> </ul> <p>The app uses Agno for agent and team orchestration, with a service-oriented Python backend under <code>services/</code> and Streamlit UI in <code>app/</code>.</p>"},{"location":"repository-overview/#2-current-implementation-status","title":"2) Current implementation status","text":"<p>The repository contains a functional MVP with active refactoring toward more modular runtime services.</p> <p>Implemented capabilities include:</p> <ul> <li>Source upload and parsing for text, office docs, images, audio, and video</li> <li>LanceDB-backed retrieval and indexing</li> <li>Streaming chat with tool-call visibility and fallback behavior</li> <li>Agent/team configuration persisted in per-agent JSON files</li> <li>Preset-driven chat model/tools/member switching</li> <li>Studio template generation and artifact persistence</li> </ul> <p>Planned and roadmap work is tracked in:</p> <ul> <li><code>AGNO_ADOPTION_BACKLOG.md</code></li> <li><code>docs_internal/HALO_CORE_PRD.md</code></li> <li><code>docs_internal/HALO_CHAT_INTEGRATION_PRD.md</code></li> </ul>"},{"location":"repository-overview/#3-high-level-structure","title":"3) High-level structure","text":"<pre><code>app/                    Streamlit app and pages\nservices/               Core business logic and orchestration\ntemplates/              Studio template registry (JSON)\ndata/                   Local runtime storage (JSON, LanceDB, generated assets)\ntests/                  Pytest suite\ndocs/                   Maintainer-facing implementation docs (this folder)\ndocs_internal/          PRDs and integration plans\nadr/                    Architecture decision records\n.github/workflows/      CI, docs lint, release, dependency audit\n</code></pre>"},{"location":"repository-overview/#4-key-runtime-entry-points","title":"4) Key runtime entry points","text":""},{"location":"repository-overview/#primary-app-entrypoint","title":"Primary app entrypoint","text":"<ul> <li><code>streamlit run app/main.py</code></li> <li>Main function: <code>run_app()</code> in <code>app/main.py</code></li> </ul>"},{"location":"repository-overview/#major-service-entrypoints","title":"Major service entrypoints","text":"<ul> <li>Chat orchestration: <code>services/chat_runtime.py::run_chat_turn</code></li> <li>Agent abstraction: <code>services/agents.py</code></li> <li>Team building: <code>services/halo_team.py</code></li> <li>Streaming normalization: <code>services/streaming_adapter.py::stream_agent_response</code></li> <li>Storage and persistence: <code>services/storage.py</code></li> <li>Source ingestion: <code>services/ingestion.py</code></li> <li>Retrieval and indexing: <code>services/retrieval.py</code></li> </ul>"},{"location":"repository-overview/#5-technology-stack","title":"5) Technology stack","text":""},{"location":"repository-overview/#application-and-orchestration","title":"Application and orchestration","text":"<ul> <li>Streamlit</li> <li>Agno</li> <li>OpenAI SDK</li> </ul>"},{"location":"repository-overview/#data-and-parsing","title":"Data and parsing","text":"<ul> <li>LanceDB + pyarrow + numpy</li> <li>pypdf, python-docx, openpyxl, python-pptx</li> <li>moviepy (video to audio extraction)</li> </ul>"},{"location":"repository-overview/#validation-and-config","title":"Validation and config","text":"<ul> <li>Pydantic + pydantic-settings</li> <li>dotenv support via dependencies</li> </ul>"},{"location":"repository-overview/#quality-and-ci","title":"Quality and CI","text":"<ul> <li>pytest</li> <li>ruff</li> <li>black</li> <li>mypy (present but currently commented in CI workflow)</li> </ul>"},{"location":"repository-overview/#6-configuration-model","title":"6) Configuration model","text":"<p>Configuration is split between:</p> <ol> <li>Environment/settings (<code>services/settings.py</code>)</li> <li><code>OPENAI_API_KEY</code></li> <li><code>HALO_DATA_DIR</code></li> <li><code>HALO_TEMPLATES_DIR</code></li> <li> <p><code>HALO_AGENT_DB</code></p> </li> <li> <p>Runtime UI configuration (<code>data/config.json</code>)</p> </li> <li>connector enablement</li> <li>logging toggles</li> <li>image model</li> <li> <p>selected preset</p> </li> <li> <p>Agent configuration (<code>HALO_DATA_DIR/agents/*.json</code>)</p> </li> <li> <p>per-agent role/instructions/tools/model/members/coordination controls</p> </li> <li> <p>Studio template registry (<code>templates/studio_templates.json</code>)</p> </li> <li> <p>data-driven template definitions</p> </li> <li> <p>Presets (<code>presets.json</code>)</p> </li> <li>quick updates for chat model/tools/members/stream/coordinator behavior</li> </ol>"},{"location":"repository-overview/#7-data-persistence-model","title":"7) Data persistence model","text":"<p>The app primarily uses local JSON and local LanceDB:</p> <ul> <li>Sources: <code>data/sources.json</code></li> <li>Chat history: <code>data/chat_history/&lt;session_id&gt;.json</code></li> <li>Studio notes: <code>data/studio_notes.json</code></li> <li>Studio outputs: <code>data/studio_outputs.json</code></li> <li>Connector cache: <code>data/connector_cache.json</code></li> <li>Retrieval index: <code>data/lancedb/</code></li> </ul> <p>Optional Agno SQLite memory backend is enabled via <code>HALO_AGENT_DB</code>.</p>"},{"location":"repository-overview/#8-ui-composition-model","title":"8) UI composition model","text":"<p>The default app view is a 3-column layout:</p> <ol> <li>Sources panel</li> <li>Chat panel</li> <li>Studio panel</li> </ol> <p>Sidebar includes navigation to multipage entries:</p> <ul> <li>Dashboard</li> <li>Configuration</li> <li>Account</li> <li>Help</li> <li>Agent Config page (reachable from Configuration page)</li> </ul>"},{"location":"repository-overview/#9-test-coverage-map","title":"9) Test coverage map","text":"<p>The <code>tests/</code> suite covers:</p> <ul> <li>Agent config validation/merging</li> <li>Team routing and coordination behavior</li> <li>Chat runtime orchestration and telemetry</li> <li>Streaming event handling and deduplication</li> <li>Chunking, ingestion, knowledge, presets, chat state</li> </ul> <p>This supports a safe refactoring path from monolithic UI logic to service-level modules.</p>"},{"location":"repository-overview/#10-cicd-overview","title":"10) CI/CD overview","text":"<p>GitHub workflows include:</p> <ul> <li><code>ci.yml</code>: lint + format + tests (Python 3.11 and 3.13)</li> <li><code>docs.yml</code>: markdown lint on PR markdown changes</li> <li><code>audit.yml</code>: scheduled dependency audit via <code>pip-audit</code></li> <li><code>release.yml</code>: Docker build on version tags</li> </ul>"},{"location":"repository-overview/#11-internal-reference-documents","title":"11) Internal reference documents","text":"<ul> <li>Product requirements: <code>docs_internal/HALO_CORE_PRD.md</code></li> <li>Chat integration PRD: <code>docs_internal/HALO_CHAT_INTEGRATION_PRD.md</code></li> <li>Agent config integration plan: <code>docs_internal/AGENT_CONFIG_INTEGRATION_PLAN.md</code></li> <li>Architecture decision: <code>adr/0001-streamlit-agno-architecture.md</code></li> <li>Collaboration/coding rules: <code>AGENTS.md</code></li> </ul>"},{"location":"repository-overview/#12-where-to-start-by-role","title":"12) Where to start (by role)","text":""},{"location":"repository-overview/#new-maintainer","title":"New maintainer","text":"<ol> <li><code>README.md</code></li> <li><code>docs/ARCHITECTURE_AND_RUNTIME.md</code></li> <li><code>docs/DEVELOPMENT_TESTING_AND_OPERATIONS.md</code></li> </ol>"},{"location":"repository-overview/#chatagent-contributor","title":"Chat/agent contributor","text":"<ol> <li><code>docs/AGENT_SYSTEM.md</code></li> <li><code>services/chat_runtime.py</code></li> <li><code>services/streaming_adapter.py</code></li> </ol>"},{"location":"repository-overview/#ingestionrag-contributor","title":"Ingestion/RAG contributor","text":"<ol> <li><code>docs/DATA_STORAGE_AND_RETRIEVAL.md</code></li> <li><code>services/ingestion.py</code></li> <li><code>services/retrieval.py</code></li> </ol>"},{"location":"repository-overview/#ui-contributor","title":"UI contributor","text":"<ol> <li><code>docs/UI_PANELS_AND_PAGES.md</code></li> <li><code>app/main.py</code></li> <li><code>app/pages/*.py</code></li> </ol>"},{"location":"ui-panels-and-pages/","title":"HALO Core UI Panels and Pages","text":""},{"location":"ui-panels-and-pages/#1-ui-architecture-at-a-glance","title":"1) UI architecture at a glance","text":"<p>The app uses Streamlit with:</p> <ul> <li>one primary 3-panel app (<code>app/main.py</code>)</li> <li>auxiliary multipage entries under <code>app/pages/</code></li> <li>session-state driven interaction model</li> </ul> <p>Primary layout in <code>run_app()</code>:</p> <ul> <li>left: Sources panel</li> <li>center: Chat panel</li> <li>right: Studio panel</li> </ul>"},{"location":"ui-panels-and-pages/#2-sidebar-navigation-and-controls","title":"2) Sidebar navigation and controls","text":"<p><code>render_sidebar()</code> exposes:</p> <ul> <li>New Notebook button (placeholder behavior)</li> <li>page navigation buttons:</li> <li>Dashboard (<code>pages/Dashboard.py</code>)</li> <li>Configuration (<code>pages/Configuration.py</code>)</li> <li>Account (<code>pages/Account.py</code>)</li> <li>Help (<code>pages/Help.py</code>)</li> <li>support caption</li> </ul> <p>If multipage routing is unavailable, error messaging is shown in sidebar.</p>"},{"location":"ui-panels-and-pages/#3-session-state-model-used-by-ui","title":"3) Session-state model used by UI","text":"<p>Core session keys initialized in <code>_init_state()</code> include:</p> <ul> <li><code>session_id</code></li> <li><code>sources</code></li> <li><code>chat_history</code></li> <li><code>persistent_tool_calls</code></li> <li><code>studio_templates</code></li> <li><code>studio_outputs</code></li> <li><code>notes</code></li> <li><code>config</code></li> <li><code>agent_configs</code></li> </ul> <p>Additional panel-specific keys are created lazily (e.g., template settings and confirmation dialog flags).</p>"},{"location":"ui-panels-and-pages/#4-sources-panel-render_sources_panel","title":"4) Sources panel (<code>render_sources_panel</code>)","text":"<p>Responsibilities:</p> <ul> <li>source creation from file upload</li> <li>source creation from web-search suggestions</li> <li>source creation from connector fetch results</li> <li>source selection toggles (used to scope chat/studio context)</li> <li>source rename/delete/bulk-delete operations</li> <li>source-to-retrieval indexing via ingestion path</li> </ul> <p>UX patterns used:</p> <ul> <li>modal dialogs (<code>st.dialog</code>) for add/rename/delete flows</li> <li>popover action menus for per-source operations</li> <li>toasts for operation feedback</li> <li>status captions and empty-state guidance</li> </ul> <p>Important behavior:</p> <ul> <li>source list is persisted in JSON</li> <li>source deletion attempts to remove indexed retrieval chunks by <code>source_id</code> and fallback by <code>title</code></li> <li>selection state is mirrored into checkbox-style state keys (<code>src_&lt;id&gt;</code>)</li> </ul>"},{"location":"ui-panels-and-pages/#5-chat-panel-render_chat_panel","title":"5) Chat panel (<code>render_chat_panel</code>)","text":"<p>Core display behavior:</p> <ul> <li>renders all chat history entries by role</li> <li>assistant messages can show:</li> <li>Agent Actions trace expander</li> <li>Tool Calls expander</li> <li>Agent Thinking expander (if present in content)</li> <li>images</li> </ul> <p>Input behavior:</p> <ul> <li>uses <code>st.chat_input</code> with:</li> <li>text</li> <li>image file upload (<code>jpg/jpeg/png</code>)</li> <li>audio capture</li> </ul> <p>When submitted:</p> <ol> <li>normalizes prompt text</li> <li>stores uploaded images to <code>uploads/</code></li> <li>transcribes audio via ingestion parser path</li> <li>appends user message to persisted history</li> <li>stores pending prompt/images in session state</li> <li>invokes chat runtime in next rerun</li> </ol> <p>Streaming behavior in UI:</p> <ul> <li>uses callbacks from <code>ChatTurnInput</code>:</li> <li><code>on_response</code> to progressively render markdown</li> <li><code>on_tools</code> to update tool call display</li> <li>final assistant message is persisted after runtime returns</li> </ul> <p>Additional feature:</p> <ul> <li>\"all sources summary\" expander with refresh and \"save as note\" actions</li> </ul>"},{"location":"ui-panels-and-pages/#6-studio-panel-render_studio_panel","title":"6) Studio panel (<code>render_studio_panel</code>)","text":"<p>High-level sections:</p> <ol> <li>template cards (generate + configure)</li> <li>studio outputs list</li> <li>chat notes section</li> </ol> <p>Template card behavior:</p> <ul> <li>values are stored per-template in session state:</li> <li>language</li> <li>tone</li> <li>instructions</li> <li>user prompt</li> <li>generation path calls pipelines and inserts output at top of list</li> <li>output metadata includes output id, template id, generated timestamp, sources, and optional image path</li> </ul> <p>Outputs section behavior:</p> <ul> <li>grouped/ordered by templates when possible</li> <li>per-output actions include:</li> <li>rename</li> <li>download markdown</li> <li>promote to source</li> <li>share placeholder</li> <li>delete with confirmation</li> </ul> <p>Notes section behavior:</p> <ul> <li>notes rendered as expandable blocks</li> <li>per-note actions include:</li> <li>rename</li> <li>download</li> <li>promote to source</li> <li>share placeholder</li> <li>delete with confirmation</li> <li>includes \"add note\" dialog</li> </ul>"},{"location":"ui-panels-and-pages/#7-configuration-surfaces","title":"7) Configuration surfaces","text":""},{"location":"ui-panels-and-pages/#71-sidebar-configuration-panel-_render_configuration_panel","title":"7.1 Sidebar configuration panel (<code>_render_configuration_panel</code>)","text":"<p>Includes controls for:</p> <ul> <li>enabled connectors</li> <li>image model selection</li> <li>logging toggles</li> <li>preset selection and apply action</li> <li>chat model/team/tools</li> <li>per-agent editor (name/role/description/instructions/tools/enabled/members)</li> </ul>"},{"location":"ui-panels-and-pages/#72-dedicated-configuration-page-pagesconfigurationpy","title":"7.2 Dedicated Configuration page (<code>pages/Configuration.py</code>)","text":"<ul> <li>renders <code>_render_configuration_panel()</code> in page context</li> <li>includes button to navigate to Agent Config page</li> </ul>"},{"location":"ui-panels-and-pages/#73-agent-config-page-pagesagent_configpy","title":"7.3 Agent Config page (<code>pages/Agent_Config.py</code>)","text":"<ul> <li>standalone editor for per-agent configs loaded from service layer</li> <li>supports key fields:</li> <li>instructions</li> <li>skills</li> <li>tools</li> <li>mcp calls</li> <li>model override</li> <li>memory scope</li> <li>coordination mode</li> <li>stream events</li> <li>enabled toggle</li> </ul>"},{"location":"ui-panels-and-pages/#8-auxiliary-pages","title":"8) Auxiliary pages","text":"<p>Current non-core pages are lightweight placeholders:</p> <ul> <li><code>pages/Dashboard.py</code></li> <li><code>pages/Account.py</code></li> <li><code>pages/Help.py</code></li> </ul> <p>They establish navigation structure but do not yet contain deep business logic.</p>"},{"location":"ui-panels-and-pages/#9-visual-design-and-css-model","title":"9) Visual design and CSS model","text":"<p>The app relies on inline CSS injected in panel render functions, especially in Studio and notes rendering.</p> <p>Notable characteristics:</p> <ul> <li>custom card-like behavior around Streamlit blocks</li> <li>compact popover controls</li> <li>visual differentiation for template header actions</li> </ul> <p>Because CSS is inline and tightly coupled to Streamlit test ids, future Streamlit version upgrades should be verified carefully for selector compatibility.</p>"},{"location":"ui-panels-and-pages/#10-ui-coupling-notes-and-maintenance-guidance","title":"10) UI coupling notes and maintenance guidance","text":"<p>Current coupling points to watch:</p> <ul> <li>some business logic still lives in <code>app/main.py</code> alongside UI rendering</li> <li>dialog flags and session keys are numerous and naming-based</li> <li>panel code includes substantial side effects (save, delete, rerun)</li> </ul> <p>Recommended maintenance approach:</p> <ol> <li>Keep UI changes local to panel/page functions.</li> <li>Prefer moving new business logic to <code>services/</code>.</li> <li>Preserve session key names unless migration is intentional.</li> <li>Add/update tests when changing chat stream or config behavior.</li> </ol>"},{"location":"ui-panels-and-pages/#11-accessibility-and-localization-notes","title":"11) Accessibility and localization notes","text":"<p>Current UI strings are mixed German/English, with German dominant in interactive labels.</p> <p>Examples:</p> <ul> <li>\"Quellen\", \"Konfigurieren\", \"L\u00f6schen\", \"Teilen\", \"Als Quelle nutzen\"</li> </ul> <p>Localization strategy is currently implicit (hard-coded strings) and could be centralized in a future i18n pass.</p>"},{"location":"user-handbook/","title":"HALO Core User Handbook","text":""},{"location":"user-handbook/#halo-signature-features-extraordinary","title":"HALO Signature Features (Extraordinary)","text":"<p>This section highlights the standout capabilities that make HALO different from a basic chat app.</p>"},{"location":"user-handbook/#1-halo-concept-and-identity","title":"1) HALO concept and identity","text":"<ul> <li>HALO = Holistic Agent Logical Orchestrator.</li> <li>The product is designed as an orchestrated intelligence workspace, not only as a single assistant chat.</li> </ul>"},{"location":"user-handbook/#2-team-based-ai-collaboration","title":"2) Team-based AI collaboration","text":"<ul> <li>HALO can run with a team of specialized agents.</li> <li>Each agent can have its own role, instructions, tools, and settings.</li> <li>This allows different expert perspectives (for example research-focused, report-focused, or tool-focused behavior).</li> </ul>"},{"location":"user-handbook/#3-smart-delegation-strategies","title":"3) Smart delegation strategies","text":"<ul> <li>HALO supports multiple delegation modes such as:</li> <li><code>direct_only</code></li> <li><code>delegate_on_complexity</code></li> <li><code>always_delegate</code></li> <li><code>coordinated_rag</code></li> <li>In practical terms: HALO can decide when to answer directly and when to involve specialist agents.</li> </ul>"},{"location":"user-handbook/#4-complexity-behind-glass-transparency","title":"4) \"Complexity behind glass\" transparency","text":"<ul> <li>Users can inspect what happened during generation via expandable sections like:</li> <li>Agent Actions</li> <li>Tool Calls</li> <li>Agent Thinking</li> <li>This gives visibility into reasoning flow and orchestration behavior without exposing raw system internals.</li> </ul>"},{"location":"user-handbook/#5-memory-management-layer-tied-to-chat-identity","title":"5) Memory Management layer tied to chat identity","text":"<ul> <li>HALO supports a memory layer linked to the active <code>user_id</code>.</li> <li>When memory backend is enabled, user memory can persist across interactions and be managed in the Account page.</li> <li>This enables more personalized continuity across chat sessions.</li> </ul>"},{"location":"user-handbook/#6-multimodal-understanding-in-one-chat-flow","title":"6) Multimodal understanding in one chat flow","text":"<ul> <li>Users can combine:</li> <li>text prompts</li> <li>image uploads</li> <li>audio input (with transcription)</li> <li>This supports richer real-world workflows (for example \"analyze this image and include my spoken notes\").</li> </ul>"},{"location":"user-handbook/#7-source-grounded-citations-with-fallback-resilience","title":"7) Source-grounded citations with fallback resilience","text":"<ul> <li>HALO is built to answer using selected sources.</li> <li>It applies citation-aware response handling and can fall back to alternate generation paths when streaming output is empty.</li> </ul>"},{"location":"user-handbook/#8-live-source-awareness-and-quick-synthesis","title":"8) Live source-awareness and quick synthesis","text":"<ul> <li>The chat area includes a dynamic summary of all sources.</li> <li>HALO tracks whether this summary is stale when source inventory changes, so users can refresh at the right moment.</li> </ul>"},{"location":"user-handbook/#9-studio-pipeline-from-insight-to-artifact","title":"9) Studio pipeline from insight to artifact","text":"<ul> <li>HALO turns research context directly into production-style outputs (report, infographic, podcast, presentation, etc.).</li> <li>Outputs are persisted, revisitable, and exportable from the same workspace.</li> </ul>"},{"location":"user-handbook/#1-overview","title":"1. Overview","text":""},{"location":"user-handbook/#what-this-application-is","title":"What this application is","text":"<p>HALO Core is a workspace app for research and content creation. It helps you: - collect sources (files, web findings, connector results) - ask questions in a source-grounded AI chat - generate ready-to-use outputs (for example reports, infographics, podcast scripts, and presentations) - save important chat results as reusable notes</p> <p>In short: HALO Core combines a document library, an AI assistant, and a content studio in one interface.</p>"},{"location":"user-handbook/#who-it-is-for","title":"Who it is for","text":"<p>HALO Core is designed for people who need to turn information into useful outputs quickly, such as: - analysts and consultants - medical or scientific researchers - content teams and editors - product and strategy teams - anyone preparing summaries, presentations, or evidence-based answers</p>"},{"location":"user-handbook/#core-problem-it-solves","title":"Core problem it solves","text":"<p>Without HALO Core, users often jump between many tools (storage, search, AI chat, notes, export tools). This creates friction and lost context.</p> <p>HALO Core solves this by keeping the full workflow in one place: 1. add sources 2. chat with context 3. convert answers into structured outputs 4. save/share/export results</p>"},{"location":"user-handbook/#key-benefits","title":"Key benefits","text":"<ul> <li>Faster research cycles: fewer app switches</li> <li>More reliable answers: chat is grounded in selected sources</li> <li>Reusable knowledge: notes and outputs persist locally</li> <li>Flexible setup: configurable models, tools, presets, and sidebar layout</li> <li>Practical output formats: markdown, PDF-like export, and slide-style CSV export</li> </ul>"},{"location":"user-handbook/#high-level-architecture-non-technical","title":"High-level architecture (non-technical)","text":"<p>At a high level, HALO Core has three visible work areas and several support pages: - Sources: your library and ingestion area - Chat: your AI conversation and source summary area - Studio: output generation and artifact management - Sidebar pages: Configuration, Account, Help, Agent Config, Dashboard</p> <p>Data is saved in local files by default, so your session can continue later.</p>"},{"location":"user-handbook/#2-getting-started","title":"2. Getting Started","text":""},{"location":"user-handbook/#prerequisites","title":"Prerequisites","text":"<p>Before running HALO Core, make sure you have: - Python 3.10+ - required Python packages from <code>requirements.txt</code> - (recommended) an OpenAI API key for full AI features - FFmpeg if you plan to transcribe audio/video</p>"},{"location":"user-handbook/#installation-and-setup","title":"Installation and setup","text":"<ol> <li>Create and activate a virtual environment.</li> <li>Install dependencies:</li> <li><code>pip install -r requirements.txt</code></li> <li>Create <code>.streamlit/secrets.toml</code> and add keys (for example <code>OPENAI_API_KEY</code>).</li> <li>Start the app:</li> <li><code>streamlit run app/main.py</code></li> </ol>"},{"location":"user-handbook/#account-creationlogin","title":"Account creation/login","text":"<p>There is no mandatory account sign-up in the UI. - By default, the app uses a local user identity (<code>local-user</code>). - Advanced users can set a custom <code>user_id</code> in configuration.</p>"},{"location":"user-handbook/#basic-first-use-flow","title":"Basic first-use flow","text":"<ol> <li>Open HALO Core.</li> <li>Add at least one source in Sources.</li> <li>Select your source(s).</li> <li>Ask a question in Chat.</li> <li>Save valuable responses as notes.</li> <li>Generate a structured output in Studio.</li> </ol> <p>Expected result: you can move from raw files to a publishable draft in one session.</p>"},{"location":"user-handbook/#3-core-features","title":"3. Core Features","text":""},{"location":"user-handbook/#a-sources-library","title":"A. Sources Library","text":""},{"location":"user-handbook/#what-it-does","title":"What it does","text":"<p>Lets you import, manage, select, and remove sources used by chat and studio generation.</p>"},{"location":"user-handbook/#why-it-matters","title":"Why it matters","text":"<p>Source selection controls what the AI can use for grounded responses.</p>"},{"location":"user-handbook/#how-to-use-it","title":"How to use it","text":"<ol> <li>In Sources, click + Quellen hinzuf\u00fcgen.</li> <li>Upload one or more files (PDF, DOCX, TXT, MD, CSV, XLSX, PPTX, images, audio, video).</li> <li>Optionally run web search suggestions and import results.</li> <li>Mark sources via checkboxes (or use \u201cselect all\u201d).</li> <li>Use per-source menu actions to rename, download, or delete.</li> </ol>"},{"location":"user-handbook/#expected-results","title":"Expected results","text":"<ul> <li>Imported items appear in the source list with type and timestamp.</li> <li>Selected sources are used by chat/studio.</li> <li>Deleted items are removed from local project state.</li> </ul>"},{"location":"user-handbook/#b-connector-based-source-collection","title":"B. Connector-Based Source Collection","text":""},{"location":"user-handbook/#what-it-does_1","title":"What it does","text":"<p>Allows fetching source suggestions from connected systems (for example Drive/Notion connectors in current build).</p>"},{"location":"user-handbook/#why-it-matters_1","title":"Why it matters","text":"<p>Helps collect source candidates faster than manual uploads.</p>"},{"location":"user-handbook/#how-to-use-it_1","title":"How to use it","text":"<ol> <li>In Sources, choose one or more connectors.</li> <li>Click Quellen abrufen.</li> <li>Review listed results.</li> <li>Click Importieren for the items you want.</li> </ol>"},{"location":"user-handbook/#expected-results_1","title":"Expected results","text":"<p>Imported connector items appear in your source list and can be selected for chat/studio.</p> <p>Assumption: Connector behavior is partly MVP/mock-backed in this repository version. Treat it as a guided ingestion layer that can be extended in production.</p>"},{"location":"user-handbook/#c-chat-with-source-grounding","title":"C. Chat with Source Grounding","text":""},{"location":"user-handbook/#what-it-does_2","title":"What it does","text":"<p>Lets you ask text questions, attach images, and capture audio-to-text prompts. Answers are generated using selected sources.</p>"},{"location":"user-handbook/#why-it-matters_2","title":"Why it matters","text":"<p>Improves trustworthiness by grounding responses in your source set.</p>"},{"location":"user-handbook/#how-to-use-it_2","title":"How to use it","text":"<ol> <li>Select sources in Sources panel.</li> <li>In Chat, enter a prompt (optional: add image/audio input).</li> <li>Send your prompt.</li> <li>Review answer, tool calls, and optional agent trace sections.</li> <li>Save useful responses as notes.</li> </ol>"},{"location":"user-handbook/#expected-results_2","title":"Expected results","text":"<ul> <li>You receive a response with source-aware behavior.</li> <li>If multiple sources are selected, responses can include a source section.</li> <li>Agent actions/tool call details can appear in expandable sections.</li> </ul>"},{"location":"user-handbook/#d-summary-of-all-sources-in-chat","title":"D. \u201cSummary of All Sources\u201d in Chat","text":""},{"location":"user-handbook/#what-it-does_3","title":"What it does","text":"<p>Creates and stores a unified summary of all sources in the library.</p>"},{"location":"user-handbook/#why-it-matters_3","title":"Why it matters","text":"<p>Gives fast orientation before deep questioning.</p>"},{"location":"user-handbook/#how-to-use-it_3","title":"How to use it","text":"<ol> <li>In the chat panel, open Zusammenfassung aller Quellen.</li> <li>Click refresh icon to generate/update summary.</li> <li>Optionally pin the summary to notes.</li> </ol>"},{"location":"user-handbook/#expected-results_3","title":"Expected results","text":"<ul> <li>Summary content is displayed.</li> <li>Stale indicator appears when source set changed.</li> <li>You can save summary as a note for later reuse.</li> </ul>"},{"location":"user-handbook/#e-studio-templates-content-generation","title":"E. Studio Templates (Content Generation)","text":""},{"location":"user-handbook/#what-it-does_4","title":"What it does","text":"<p>Generates structured deliverables from your current context via template cards.</p> <p>Current template set includes: - Bericht (Report) - Infografik - Podcast - Video\u00fcbersicht - Pr\u00e4sentation - Datentabelle</p>"},{"location":"user-handbook/#why-it-matters_4","title":"Why it matters","text":"<p>Transforms chat/research context into actionable artifacts quickly.</p>"},{"location":"user-handbook/#how-to-use-it_4","title":"How to use it","text":"<ol> <li>Open Studio.</li> <li>Pick a template card.</li> <li>(Optional) open card menu to set language, tone, and extra prompt.</li> <li>Click template generate button.</li> <li>Review saved output in Studio-Ergebnisse.</li> </ol>"},{"location":"user-handbook/#expected-results_4","title":"Expected results","text":"<ul> <li>A new output artifact appears in Studio results.</li> <li>Output includes generation timestamp and linked source context.</li> <li>You can expand, review, and export/delete outputs.</li> </ul>"},{"location":"user-handbook/#f-notes-management","title":"F. Notes Management","text":""},{"location":"user-handbook/#what-it-does_5","title":"What it does","text":"<p>Stores reusable notes captured from chat, summaries, or manual entry.</p>"},{"location":"user-handbook/#why-it-matters_5","title":"Why it matters","text":"<p>Preserves key findings and allows reusing them as sources.</p>"},{"location":"user-handbook/#how-to-use-it_5","title":"How to use it","text":"<ol> <li>Save a chat response or source summary as note.</li> <li>In notes section, expand a note to read content and source info.</li> <li>Use menu actions to rename, download, delete, or convert note into a source.</li> <li>Add manual notes with Notiz hinzuf\u00fcgen.</li> </ol>"},{"location":"user-handbook/#expected-results_5","title":"Expected results","text":"<ul> <li>Notes persist across sessions.</li> <li>Converted notes appear as selectable sources.</li> </ul>"},{"location":"user-handbook/#g-configuration-hub","title":"G. Configuration Hub","text":""},{"location":"user-handbook/#what-it-does_6","title":"What it does","text":"<p>Central place for app setup, split into tabs: - App (design/menu/theme/sidebar behavior) - Sources (connectors, image model) - Chat (logging, presets, model/tools/team) - Studio (template settings) - Advanced (agent-level controls)</p>"},{"location":"user-handbook/#why-it-matters_6","title":"Why it matters","text":"<p>Lets you tailor workflow and appearance to your team\u2019s needs.</p>"},{"location":"user-handbook/#how-to-use-it_6","title":"How to use it","text":"<ol> <li>Open Configuration from sidebar.</li> <li>Navigate to relevant tab.</li> <li>Change values.</li> <li>Save in-section settings.</li> </ol>"},{"location":"user-handbook/#expected-results_6","title":"Expected results","text":"<p>Updated configuration persists and affects runtime behavior.</p>"},{"location":"user-handbook/#h-account-memory-management","title":"H. Account Memory Management","text":""},{"location":"user-handbook/#what-it-does_7","title":"What it does","text":"<p>Displays and manages user memory entries when memory DB backend is enabled.</p>"},{"location":"user-handbook/#why-it-matters_7","title":"Why it matters","text":"<p>Lets users clean up or reset saved memory traces.</p>"},{"location":"user-handbook/#how-to-use-it_7","title":"How to use it","text":"<ol> <li>Open Account page.</li> <li>If enabled, review memory rows.</li> <li>Select entries and delete selected, or clear all.</li> </ol>"},{"location":"user-handbook/#expected-results_7","title":"Expected results","text":"<ul> <li>Selected memory entries are removed.</li> <li>If backend is disabled, page informs you clearly.</li> </ul>"},{"location":"user-handbook/#i-agent-configuration-power-feature","title":"I. Agent Configuration (Power Feature)","text":""},{"location":"user-handbook/#what-it-does_8","title":"What it does","text":"<p>Provides deep control of per-agent settings, including tools, MCP servers, role instructions, and coordination mode.</p>"},{"location":"user-handbook/#why-it-matters_8","title":"Why it matters","text":"<p>Enables advanced workflow specialization by role/use case.</p>"},{"location":"user-handbook/#how-to-use-it_8","title":"How to use it","text":"<ol> <li>Open Configuration \u2192 Open Agent Config.</li> <li>Select an agent.</li> <li>Edit fields (name, role, instructions, tool list, runtime settings).</li> <li>Save configuration.</li> </ol>"},{"location":"user-handbook/#expected-results_8","title":"Expected results","text":"<p>Selected agent behavior updates for subsequent runs.</p>"},{"location":"user-handbook/#4-workflows-common-tasks","title":"4. Workflows / Common Tasks","text":""},{"location":"user-handbook/#workflow-1-ask-grounded-questions-on-uploaded-documents","title":"Workflow 1: Ask grounded questions on uploaded documents","text":"<ol> <li>Upload PDFs/DOCX files in Sources.</li> <li>Select them with checkboxes.</li> <li>Ask a focused question in Chat.</li> <li>Save the best answer as note.</li> </ol> <p>Result: you get a traceable answer tied to selected material.</p>"},{"location":"user-handbook/#workflow-2-build-a-report-draft-from-collected-evidence","title":"Workflow 2: Build a report draft from collected evidence","text":"<ol> <li>Import sources (uploads + connectors).</li> <li>Generate/update all-sources summary.</li> <li>Open Studio and choose Bericht.</li> <li>Set language/tone and add optional prompt.</li> <li>Generate and export.</li> </ol> <p>Result: report-style draft you can refine externally.</p>"},{"location":"user-handbook/#workflow-3-convert-insights-into-presentation-ready-structure","title":"Workflow 3: Convert insights into presentation-ready structure","text":"<ol> <li>Prepare source set and chat findings.</li> <li>Save key findings as notes.</li> <li>Use Pr\u00e4sentation template.</li> <li>Export output as needed.</li> </ol> <p>Result: rapid first draft of slide flow.</p>"},{"location":"user-handbook/#workflow-4-manage-long-running-project-memory","title":"Workflow 4: Manage long-running project memory","text":"<ol> <li>Use Account page to review memory items.</li> <li>Delete outdated entries.</li> <li>Keep only useful context.</li> </ol> <p>Result: cleaner assistant behavior and reduced noise.</p>"},{"location":"user-handbook/#5-interface-explanation","title":"5. Interface Explanation","text":""},{"location":"user-handbook/#main-layout","title":"Main layout","text":"<p>The default Home view has three columns: 1. Sources (left) 2. Chat (center) 3. Studio (right)</p>"},{"location":"user-handbook/#sidebar","title":"Sidebar","text":"<p>The sidebar is fully configurable and can include: - navigation links - separators/spacers - theme toggle - branding logo/icon</p> <p>Default destinations include Home, Dashboard, Configuration, Account, Help.</p>"},{"location":"user-handbook/#key-controls-you-will-use-often","title":"Key controls you will use often","text":"<ul> <li>+ Quellen hinzuf\u00fcgen: import sources</li> <li>Quellen abrufen: fetch connector data</li> <li>Chat input: question/audio/image submission</li> <li>In Notiz speichern: keep chat output</li> <li>Template Generate button: create studio artifact</li> <li>Download buttons: export source/note/output content</li> <li>Configuration save buttons: persist setting changes</li> </ul>"},{"location":"user-handbook/#important-page-summaries","title":"Important page summaries","text":"<ul> <li>Dashboard: placeholder status page in current build</li> <li>Configuration: operational control center</li> <li>Account: memory management</li> <li>Help: support pointers</li> <li>Agent Config: advanced AI behavior setup</li> </ul>"},{"location":"user-handbook/#6-advanced-usage","title":"6. Advanced Usage","text":""},{"location":"user-handbook/#a-theme-and-navigation-customization","title":"A. Theme and navigation customization","text":"<p>In Configuration \u2192 App, you can customize: - colors (background/text/hover/separator) - icon and font sizes - collapsed/expanded sidebar widths - menu entry order and item types (link/spacer/separator/theme toggle) - branding assets (light/dark logo and icon)</p>"},{"location":"user-handbook/#b-chat-presets","title":"B. Chat presets","text":"<p>In Configuration \u2192 Chat: - select preset - apply model/tools/member bundle in one step</p> <p>This is useful for switching between workflows (for example quick response vs deeper multi-agent mode).</p>"},{"location":"user-handbook/#c-tool-and-coordination-tuning","title":"C. Tool and coordination tuning","text":"<p>In Agent Config you can tune: - enabled tools per agent - MCP server list and enabled state - coordination mode (<code>direct_only</code>, <code>delegate_on_complexity</code>, <code>always_delegate</code>, <code>coordinated_rag</code>) - stream-events behavior</p>"},{"location":"user-handbook/#d-storage-and-runtime-environment","title":"D. Storage and runtime environment","text":"<p>By environment settings, advanced users can change: - data directory location (<code>HALO_DATA_DIR</code>) - optional memory DB backend (<code>HALO_AGENT_DB</code>)</p>"},{"location":"user-handbook/#7-troubleshooting","title":"7. Troubleshooting","text":""},{"location":"user-handbook/#problem-i-get-weak-or-generic-answers","title":"Problem: \u201cI get weak or generic answers\u201d","text":"<p>Possible causes: - no sources selected - source summary outdated - missing API key</p> <p>Try this: 1. Confirm selected sources in Sources panel. 2. Refresh all-sources summary. 3. Verify <code>OPENAI_API_KEY</code> is configured.</p>"},{"location":"user-handbook/#problem-my-uploaded-file-fails-to-import","title":"Problem: \u201cMy uploaded file fails to import\u201d","text":"<p>Possible causes: - unsupported extension - parsing/transcription dependency missing</p> <p>Try this: 1. Check supported file type list. 2. For audio/video, ensure required dependencies (for example FFmpeg stack). 3. Retry with a smaller or simpler file.</p>"},{"location":"user-handbook/#problem-account-page-says-memory-backend-disabled","title":"Problem: \u201cAccount page says memory backend disabled\u201d","text":"<p>Cause: - optional memory DB is not configured.</p> <p>Try this: 1. Set <code>HALO_AGENT_DB</code> in environment. 2. Restart app.</p>"},{"location":"user-handbook/#problem-preset-list-is-empty","title":"Problem: \u201cPreset list is empty\u201d","text":"<p>Cause: - <code>presets.json</code> missing or invalid.</p> <p>Try this: 1. Add a valid <code>presets.json</code> in project root. 2. Reopen Configuration \u2192 Chat.</p>"},{"location":"user-handbook/#problem-share-action-does-nothing","title":"Problem: \u201cShare action does nothing\u201d","text":"<p>Cause: - share controls are placeholder UX in this build.</p> <p>Try this instead: - use download/export and external sharing channels.</p>"},{"location":"user-handbook/#problem-no-studio-outputs-generated","title":"Problem: \u201cNo studio outputs generated\u201d","text":"<p>Possible causes: - no relevant selected source context - model/tool configuration issue</p> <p>Try this: 1. Confirm source selection. 2. Test with Bericht template first. 3. Check chat and agent configuration.</p>"},{"location":"user-handbook/#8-faq","title":"8. FAQ","text":""},{"location":"user-handbook/#q1-do-i-need-an-account-to-use-halo-core","title":"Q1: Do I need an account to use HALO Core?","text":"<p>No mandatory signup is required in the default local setup.</p>"},{"location":"user-handbook/#q2-where-is-my-data-stored","title":"Q2: Where is my data stored?","text":"<p>By default in local JSON files under the <code>data/</code> directory.</p>"},{"location":"user-handbook/#q3-can-i-use-only-one-source","title":"Q3: Can I use only one source?","text":"<p>Yes. You can select one or many sources per task.</p>"},{"location":"user-handbook/#q4-can-i-change-the-ai-model","title":"Q4: Can I change the AI model?","text":"<p>Yes. Use Configuration (Chat tab) or Agent Config.</p>"},{"location":"user-handbook/#q5-can-i-control-which-tools-an-agent-uses","title":"Q5: Can I control which tools an agent uses?","text":"<p>Yes. Use Agent Config tool selection and settings.</p>"},{"location":"user-handbook/#q6-can-i-export-generated-outputs","title":"Q6: Can I export generated outputs?","text":"<p>Yes. Outputs and notes can be downloaded.</p>"},{"location":"user-handbook/#q7-is-every-connector-production-ready","title":"Q7: Is every connector production-ready?","text":"<p>Not necessarily in this repository snapshot. Some connector flows are MVP/mock-oriented.</p>"},{"location":"user-handbook/#q8-can-i-use-images-and-audio-in-chat","title":"Q8: Can I use images and audio in chat?","text":"<p>Yes. Chat input supports images and audio capture/import.</p>"},{"location":"user-handbook/#q9-what-if-chat-streaming-fails","title":"Q9: What if chat streaming fails?","text":"<p>The runtime has fallback behavior to still generate responses when possible.</p>"},{"location":"user-handbook/#q10-how-do-i-reset-menusidebar-customization","title":"Q10: How do I reset menu/sidebar customization?","text":"<p>Use Configuration \u2192 App and reset sidebar menu settings.</p>"},{"location":"user-handbook/#9-glossary","title":"9. Glossary","text":"<ul> <li>Source: Any imported content item used as knowledge input.</li> <li>Grounded answer: Response tied to selected sources rather than pure free-form output.</li> <li>Connector: Integration path to external systems for source discovery.</li> <li>Template: Predefined studio output type (report, infographic, etc.).</li> <li>Studio output: Generated artifact saved in Studio-Ergebnisse.</li> <li>Note: Saved text snippet from chat/summary/manual input.</li> <li>Preset: Saved chat setup bundle (model/tools/members).</li> <li>Agent: AI role with its own instructions and tools.</li> <li>Coordination mode: Rule for how master and team agents collaborate.</li> <li>MCP server: External capability endpoint used by agents for additional tool access.</li> <li>Stream events: Real-time internal events shown during response generation.</li> <li>Memory backend: Optional database layer for persistent user/agent memory.</li> </ul>"},{"location":"user-handbook/#assumptions-and-scope-notes","title":"Assumptions and Scope Notes","text":"<ul> <li>This handbook reflects the behavior of the repository state analyzed in <code>halo_core</code> at the provided path.</li> <li>Some UI labels are in German; this handbook keeps English structure with practical terminology.</li> <li>Connector and sharing flows include MVP/placeholder behavior in this version.</li> <li>This guide focuses on end users and operators, not internal developers.</li> </ul>"}]}